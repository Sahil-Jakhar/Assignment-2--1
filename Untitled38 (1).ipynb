{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb5d61ef",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769ffcbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (4.9.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: outcome in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53dd9a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26f004fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\Webb Driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a44a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automted chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7fc8084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question-\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\") \n",
    "designation.send_keys('Data analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0503a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering Location banglore in location search bar\n",
    "#search_field_loc=driver.find_element_by_class_name('suggestor-input') #here for location same class name came so we have to use absolute xpath\n",
    "#search_field_loc.send_keys('banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "857ddf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div[1]/div[1]/div/input\")\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12eed473",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "decdab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50b460d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping campany name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a051e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e6cd8f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Banking Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, G...</td>\n",
       "      <td>Coforge</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dpdzero</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "0                      Data Analyst   \n",
       "1                      Data Analyst   \n",
       "2  Data Analyst - IIT/BITS/Startups   \n",
       "3            Data Analyst - FinTech   \n",
       "4            Data Analyst - FinTech   \n",
       "5            Data Analyst - FinTech   \n",
       "6  Data Analyst - IIT/BITS/Startups   \n",
       "7                      Data Analyst   \n",
       "8              Banking Data Analyst   \n",
       "9                      Data Analyst   \n",
       "\n",
       "                                            Location  Company_name Experience  \n",
       "0                                Bangalore/Bengaluru           ANZ    6-9 Yrs  \n",
       "1                                Bangalore/Bengaluru           ANZ   6-10 Yrs  \n",
       "2                                Bangalore/Bengaluru  AVE Promagne    1-5 Yrs  \n",
       "3  Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...  Primo Hiring    1-2 Yrs  \n",
       "4  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...  Primo Hiring    1-2 Yrs  \n",
       "5  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...  Primo Hiring    1-2 Yrs  \n",
       "6                                Bangalore/Bengaluru  AVE Promagne    1-5 Yrs  \n",
       "7                                Bangalore/Bengaluru       Siemens    4-6 Yrs  \n",
       "8  Hyderabad/Secunderabad, Bangalore/Bengaluru, G...       Coforge   5-10 Yrs  \n",
       "9                                Bangalore/Bengaluru       Dpdzero    1-3 Yrs  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5815ef8",
   "metadata": {},
   "source": [
    "Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "807a2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (4.9.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5133dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc7e9781",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\Webb Driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b24ffca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automted chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33e20592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question-\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \") \n",
    "designation.send_keys( 'Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8eea8238",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div[1]/div[1]/div/input\")\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "489295e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d5defe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84a9377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping campany name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f6355aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06c52d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>5-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Persistent</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist- Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science Analyst - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science Analyst Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Analytics Specialist - Artificial Intelligence...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>7-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>7-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                                 Data Scientist_NLP   \n",
       "2                    Machine Learning (AI) Architect   \n",
       "3                               Data Science Analyst   \n",
       "4                          Data Scientist- Bangalore   \n",
       "5                                     Data Scientist   \n",
       "6                Data Science Analyst - Data Science   \n",
       "7                  Data Science Analyst Data Science   \n",
       "8  Analytics Specialist - Artificial Intelligence...   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                            Location       Company_name  \\\n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...          Accenture   \n",
       "1  Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...  Fractal Analytics   \n",
       "2  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...         Persistent   \n",
       "3                                Bangalore/Bengaluru          Accenture   \n",
       "4                                Bangalore/Bengaluru   Trigent Software   \n",
       "5                                Bangalore/Bengaluru                IBM   \n",
       "6                                Bangalore/Bengaluru          Accenture   \n",
       "7                                Bangalore/Bengaluru          Accenture   \n",
       "8                                Bangalore/Bengaluru          Accenture   \n",
       "9                                Bangalore/Bengaluru            Walmart   \n",
       "\n",
       "  Experience  \n",
       "0    2-4 Yrs  \n",
       "1   5-11 Yrs  \n",
       "2   5-12 Yrs  \n",
       "3    3-5 Yrs  \n",
       "4    3-6 Yrs  \n",
       "5   7-12 Yrs  \n",
       "6    3-5 Yrs  \n",
       "7    3-5 Yrs  \n",
       "8   7-11 Yrs  \n",
       "9    7-9 Yrs  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91510b3d",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "ASSIGNMENT 2\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results. \n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10165255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (4.9.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1d4e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1681c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\Webb Driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1863b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automted chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69ac1aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question-\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \") \n",
    "designation.send_keys( 'Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62c0eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div[1]/div[1]/div/input\")\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83646633",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "487ee8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "job_salary=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e40427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "\n",
    "    \n",
    "# scraping campany name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "491c490e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c4be75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Banking Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, G...</td>\n",
       "      <td>Coforge</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dpdzero</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Banking Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, G...</td>\n",
       "      <td>Coforge</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dpdzero</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title  \\\n",
       "0                       Data Analyst   \n",
       "1                       Data Analyst   \n",
       "2   Data Analyst - IIT/BITS/Startups   \n",
       "3             Data Analyst - FinTech   \n",
       "4             Data Analyst - FinTech   \n",
       "5             Data Analyst - FinTech   \n",
       "6   Data Analyst - IIT/BITS/Startups   \n",
       "7                       Data Analyst   \n",
       "8               Banking Data Analyst   \n",
       "9                       Data Analyst   \n",
       "10                      Data Analyst   \n",
       "11                      Data Analyst   \n",
       "12  Data Analyst - IIT/BITS/Startups   \n",
       "13            Data Analyst - FinTech   \n",
       "14            Data Analyst - FinTech   \n",
       "15            Data Analyst - FinTech   \n",
       "16  Data Analyst - IIT/BITS/Startups   \n",
       "17                      Data Analyst   \n",
       "18              Banking Data Analyst   \n",
       "19                      Data Analyst   \n",
       "\n",
       "                                             Location  Company_name Experience  \n",
       "0                                 Bangalore/Bengaluru           ANZ    6-9 Yrs  \n",
       "1                                 Bangalore/Bengaluru           ANZ   6-10 Yrs  \n",
       "2                                 Bangalore/Bengaluru  AVE Promagne    1-5 Yrs  \n",
       "3   Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...  Primo Hiring    1-2 Yrs  \n",
       "4   Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...  Primo Hiring    1-2 Yrs  \n",
       "5   Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...  Primo Hiring    1-2 Yrs  \n",
       "6                                 Bangalore/Bengaluru  AVE Promagne    1-5 Yrs  \n",
       "7                                 Bangalore/Bengaluru       Siemens    4-6 Yrs  \n",
       "8   Hyderabad/Secunderabad, Bangalore/Bengaluru, G...       Coforge   5-10 Yrs  \n",
       "9                                 Bangalore/Bengaluru       Dpdzero    1-3 Yrs  \n",
       "10                                Bangalore/Bengaluru           ANZ    6-9 Yrs  \n",
       "11                                Bangalore/Bengaluru           ANZ   6-10 Yrs  \n",
       "12                                Bangalore/Bengaluru  AVE Promagne    1-5 Yrs  \n",
       "13  Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...  Primo Hiring    1-2 Yrs  \n",
       "14  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...  Primo Hiring    1-2 Yrs  \n",
       "15  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...  Primo Hiring    1-2 Yrs  \n",
       "16                                Bangalore/Bengaluru  AVE Promagne    1-5 Yrs  \n",
       "17                                Bangalore/Bengaluru       Siemens    4-6 Yrs  \n",
       "18  Hyderabad/Secunderabad, Bangalore/Bengaluru, G...       Coforge   5-10 Yrs  \n",
       "19                                Bangalore/Bengaluru       Dpdzero    1-3 Yrs  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c6e8f",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "required data asusual\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page asusual\n",
    "6. Repeat this until you get data for 100sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "83dfdcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (4.9.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: outcome in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4765b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0b0ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "\n",
    "driver = webdriver.Chrome(\"C:\\Webb Driver\\chromedriver.exe\")\n",
    "maximize = driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b24dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onpening the flipkart website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac05574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “sunglasses” and click search button \n",
    "designation = driver.find_element(By.CLASS_NAME,'_3704LK')\n",
    "designation.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2671252",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eba89f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "\n",
    "ProductDescription = []\n",
    "\n",
    "Price= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7f80bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# scraping Brand from the given page\n",
    "brand_tags = driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "for i in brand_tags[0:100]:\n",
    "    brand=i.text\n",
    "    Brand.append(Brand)\n",
    "\n",
    "# scraping Product_Description from the given page\n",
    "productdescription_tags= driver.find_elements(By.XPATH,\"//a[@class='_2Tpdn3 _18hQoS']\")\n",
    "for i in productdescription_tags[0:100]:\n",
    "    productdescription=i.text\n",
    "    ProductDescription .append (ProductDescription)    \n",
    "\n",
    "# scraping Price from the given page\n",
    "price = driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "for i in price[0:100]:\n",
    "    price=i.text\n",
    "    Price.append(price)     \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42467afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 0 4\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(ProductDescription ),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02e11903",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBrand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mBrand\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProduct_Description\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mProductDescription\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mprice\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Brand':Brand,'Product_Description':ProductDescription ,'price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefea58b",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market \n",
    "place=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99b75e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (4.9.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdace9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8b11ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "\n",
    "driver = webdriver.Chrome(\"C:\\Webb Driver\\chromedriver.exe\")\n",
    "maximize = driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "835de286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onpening the flipkart website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45a0e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “iphone11” and click search button \n",
    "\n",
    "search_product = driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search_product.send_keys('iphone11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32d76a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []\n",
    "\n",
    "rating = driver.find_elements(By.XPATH,\"//div[@class='_2gmUFU _3V8rao']\")\n",
    "review = driver.find_elements(By.XPATH,\"//p[@class='_3879cV']\")\n",
    "full_review = driver.find_elements(By.XPATH,\"//div[@class='']\")\n",
    "\n",
    "#for page in range(0,100):\n",
    "for i in rating[0:100]:\n",
    "    Rating.append(i.text)\n",
    "for o in review[0:100]:\n",
    "    Review_summary.append(o.text)\n",
    "for p in full_review[0:100]:\n",
    "    Full_review.append(p.text)    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19a2aa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e746907d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#lets  make dataframe from the scraped data\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mrating\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReview_summary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mreview\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFull_review\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mfull_review\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m df\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#lets  make dataframe from the scraped data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Rating':rating,'Review_summary':review,'Full_review':full_review})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281581e",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5779b8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (4.9.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1177e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "100091a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "\n",
    "driver = webdriver.Chrome(\"C:\\Webb Driver\\chromedriver.exe\")\n",
    "maximize = driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8826acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onpening the flipkart website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d314793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “sneakers” and click search button \n",
    "\n",
    "search_product = driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search_product.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2c63fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f56376a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Product_Description = []\n",
    "Price= []\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    brand = driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in brand:Brand.append(i.text)\n",
    "    \n",
    "    product_des = driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in product_des:Product_Description.append(i.text)    \n",
    "    \n",
    "    price = driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in price:Price.append(i.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2e0994dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 120 40\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(Product_Description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0c50a53c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [109]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBrand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mbrand\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProduct_Description\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mProductDescription\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mprice\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Brand':brand,'Product_Description':ProductDescription ,'price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c7c7a",
   "metadata": {},
   "source": [
    "Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then \n",
    "set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d91f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (4.9.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jakha\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991e0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "325b048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\Webb Driver\\chromedriver.exe\")\n",
    "maximize = driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c09f5818",
   "metadata": {},
   "outputs": [],
   "source": [
    " #onpening the amazon website on automated chrome window\n",
    "driver.get('https://www.amazon.in/')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "85fc71d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".nav-input nav-progressive-attribute\"}\n  (Session info: chrome=113.0.5672.64)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x005B8893+48451]\n\t(No symbol) [0x0054B8A1]\n\t(No symbol) [0x00455058]\n\t(No symbol) [0x00480467]\n\t(No symbol) [0x0048069B]\n\t(No symbol) [0x004ADD92]\n\t(No symbol) [0x0049A304]\n\t(No symbol) [0x004AC482]\n\t(No symbol) [0x0049A0B6]\n\t(No symbol) [0x00477E08]\n\t(No symbol) [0x00478F2D]\n\tGetHandleVerifier [0x00818E3A+2540266]\n\tGetHandleVerifier [0x00858959+2801161]\n\tGetHandleVerifier [0x0085295C+2776588]\n\tGetHandleVerifier [0x00642280+612144]\n\t(No symbol) [0x00554F6C]\n\t(No symbol) [0x005511D8]\n\t(No symbol) [0x005512BB]\n\t(No symbol) [0x00544857]\n\tBaseThreadInitThunk [0x75CA7D49+25]\n\tRtlInitializeExceptionChain [0x7723B74B+107]\n\tRtlClearBits [0x7723B6CF+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [114]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#search the “Laptop” and click search button \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m search_product \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnav-input nav-progressive-attribute\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m search_product\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLaptop\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:831\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    828\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    829\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".nav-input nav-progressive-attribute\"}\n  (Session info: chrome=113.0.5672.64)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x005B8893+48451]\n\t(No symbol) [0x0054B8A1]\n\t(No symbol) [0x00455058]\n\t(No symbol) [0x00480467]\n\t(No symbol) [0x0048069B]\n\t(No symbol) [0x004ADD92]\n\t(No symbol) [0x0049A304]\n\t(No symbol) [0x004AC482]\n\t(No symbol) [0x0049A0B6]\n\t(No symbol) [0x00477E08]\n\t(No symbol) [0x00478F2D]\n\tGetHandleVerifier [0x00818E3A+2540266]\n\tGetHandleVerifier [0x00858959+2801161]\n\tGetHandleVerifier [0x0085295C+2776588]\n\tGetHandleVerifier [0x00642280+612144]\n\t(No symbol) [0x00554F6C]\n\t(No symbol) [0x005511D8]\n\t(No symbol) [0x005512BB]\n\t(No symbol) [0x00544857]\n\tBaseThreadInitThunk [0x75CA7D49+25]\n\tRtlInitializeExceptionChain [0x7723B74B+107]\n\tRtlClearBits [0x7723B6CF+191]\n"
     ]
    }
   ],
   "source": [
    "#search the “Laptop” and click search button \n",
    "\n",
    "search_product = driver.find_element(By.CLASS_NAME,'nav-input nav-progressive-attribute')\n",
    "search_product.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7ff7dad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=113.0.5672.64)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x005B8893+48451]\n\t(No symbol) [0x0054B8A1]\n\t(No symbol) [0x00454F20]\n\t(No symbol) [0x0047CB96]\n\t(No symbol) [0x0047C401]\n\t(No symbol) [0x0049A2BC]\n\t(No symbol) [0x00479586]\n\t(No symbol) [0x0049A614]\n\t(No symbol) [0x004AC482]\n\t(No symbol) [0x0049A0B6]\n\t(No symbol) [0x00477E08]\n\t(No symbol) [0x00478F2D]\n\tGetHandleVerifier [0x00818E3A+2540266]\n\tGetHandleVerifier [0x00858959+2801161]\n\tGetHandleVerifier [0x0085295C+2776588]\n\tGetHandleVerifier [0x00642280+612144]\n\t(No symbol) [0x00554F6C]\n\t(No symbol) [0x005511D8]\n\t(No symbol) [0x005512BB]\n\t(No symbol) [0x00544857]\n\tBaseThreadInitThunk [0x75CA7D49+25]\n\tRtlInitializeExceptionChain [0x7723B74B+107]\n\tRtlClearBits [0x7723B6CF+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [113]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#search the “Laptop” and click search button \u001b[39;00m\n\u001b[0;32m      3\u001b[0m search_product \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCLASS_NAME,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnav-search-field \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43msearch_product\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLaptop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webelement.py:231\u001b[0m, in \u001b[0;36mWebElement.send_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    228\u001b[0m             remote_files\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload(file))\n\u001b[0;32m    229\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remote_files)\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSEND_KEYS_TO_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys_to_typing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys_to_typing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webelement.py:403\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    401\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    402\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=113.0.5672.64)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x005B8893+48451]\n\t(No symbol) [0x0054B8A1]\n\t(No symbol) [0x00454F20]\n\t(No symbol) [0x0047CB96]\n\t(No symbol) [0x0047C401]\n\t(No symbol) [0x0049A2BC]\n\t(No symbol) [0x00479586]\n\t(No symbol) [0x0049A614]\n\t(No symbol) [0x004AC482]\n\t(No symbol) [0x0049A0B6]\n\t(No symbol) [0x00477E08]\n\t(No symbol) [0x00478F2D]\n\tGetHandleVerifier [0x00818E3A+2540266]\n\tGetHandleVerifier [0x00858959+2801161]\n\tGetHandleVerifier [0x0085295C+2776588]\n\tGetHandleVerifier [0x00642280+612144]\n\t(No symbol) [0x00554F6C]\n\t(No symbol) [0x005511D8]\n\t(No symbol) [0x005512BB]\n\t(No symbol) [0x00544857]\n\tBaseThreadInitThunk [0x75CA7D49+25]\n\tRtlInitializeExceptionChain [0x7723B74B+107]\n\tRtlClearBits [0x7723B6CF+191]\n"
     ]
    }
   ],
   "source": [
    "#search the “Laptop” and click search button \n",
    "\n",
    "search_product = driver.find_element(By.CLASS_NAME,'nav-search-field ')\n",
    "search_product.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba6625ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = []\n",
    "Rating = []\n",
    "Price = []\n",
    "\n",
    "Title = driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "rating = driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "Price= driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "\n",
    "#for page in range(0,100):\n",
    "for i in Title[0:100]:\n",
    "    Title.append(i.text)\n",
    "for i in Rating[0:100]:\n",
    "    Rating.append(o.text)\n",
    "for i in Price[0:100]:\n",
    "    Price.append(p.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "796b6842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Rating),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28779929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Title, rating, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':Title,'rating':rating ,'Price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433ef8b",
   "metadata": {},
   "source": [
    "Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e767f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ef79c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\Webb Driver\\chromedriver.exe\")\n",
    "maximize = driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d963637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onpening the azquotes website on automated chrome window\n",
    "driver.get('https://www.azquotes.com/')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ce56ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Quotes” and click search button \n",
    "\n",
    "search_product = driver.find_element(By.CLASS_NAME,'ui-autocomplete-input')\n",
    "search_product.send_keys('Quotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1579da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"collapse\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b90c66b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3498983233.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [123]\u001b[1;36m\u001b[0m\n\u001b[1;33m    Type Of Quotes = []\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Quote = []\n",
    "Author = []\n",
    "Type Of Quotes = []\n",
    "\n",
    "Quote = driver.find_elements(By.XPATH,\"//p[@class='gs-title']\")\n",
    "Author = driver.find_elements(By.XPATH,\"//div[@class='gs-bidi-start-align gs-snippet']\")\n",
    "Type Of Quotes= driver.find_elements(By.XPATH,\"//div[@class='gs-bidi-start-align gs-snippet']\")\n",
    "\n",
    "#for page in range(0,100):\n",
    "for i in Quote[0:100]:\n",
    "    Quote.append(i.text)\n",
    "for i in Author[0:100]:\n",
    "    Author.append(o.text)\n",
    "for i in Type Of Quotes[0:100]:\n",
    "    Type Of Quotes.append(p.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455e7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e5c168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e21c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef65aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f832424f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc4b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6e3f2d7",
   "metadata": {},
   "source": [
    "Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, \n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "81a14b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "451e587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\Webb Driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70a9305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the jagranjosh page on automted chrome browser\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "736fec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question-\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"searchBox\") \n",
    "designation.send_keys('former Prime Ministers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "125bc2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div/div[1]/div/div[3]/div/div/div/form/div[2]/div/input[1]\")\n",
    "location.send_keys('India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3cd6ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"search_expend\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c2eadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Born_Dead = []\n",
    "Term_of_office = []\n",
    "Remarks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5b740cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Name from the given page\n",
    "Name_tags=driver.find_elements(By.XPATH,'//a[@class=\"/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]/table/tbody/tr[2]/td[2]/p/strong/a\"]')\n",
    "for i in Name_tags[0:10]:\n",
    "    Name=i.text\n",
    "    Name.append(Name)\n",
    "    \n",
    "# scraping Born_Dead from the given page\n",
    "Born_Dead_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in Born_Dead_tags[0:10]:\n",
    "    Born_Dead=i.text\n",
    "    Born_Dead.append(Born_Dead)\n",
    "    \n",
    "# scraping Term_of_office from the given page\n",
    "Term_of_office_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in Term_of_office_tags[0:10]:\n",
    "    Term_of_office=i.text\n",
    "    Term_of_office.append(Term_of_office)\n",
    "    \n",
    "# scraping Remarks from the given page\n",
    "Remarks_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in Remarks_tags[0:10]:\n",
    "    Remarks=i.text\n",
    "    Remarks.append(Remarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5fb69efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Born_Dead),len(Term_of_office ),len(Remarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ad0dc6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born_Dead</th>\n",
       "      <th>Term_of_office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Born_Dead, Term_of_office , Remarks]\n",
       "Index: []"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Name':Name,'Born_Dead':Born_Dead,'Term_of_office ':Term_of_office ,'Remarks':Remarks})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cea393",
   "metadata": {},
   "source": [
    "Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. \n",
    "Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.motor1.com/\n",
    "2. Then You have to click on the List option from Dropdown menu on leftside.\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1d30db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "import pandas as pd \n",
    "from selenium import webdriver \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e1d60c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\Webb Driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5ad56a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the motor1 page on automted chrome browser\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c056609d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".m1-search-form\"}\n  (Session info: chrome=113.0.5672.64)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x005B8893+48451]\n\t(No symbol) [0x0054B8A1]\n\t(No symbol) [0x00455058]\n\t(No symbol) [0x00480467]\n\t(No symbol) [0x0048069B]\n\t(No symbol) [0x004ADD92]\n\t(No symbol) [0x0049A304]\n\t(No symbol) [0x004AC482]\n\t(No symbol) [0x0049A0B6]\n\t(No symbol) [0x00477E08]\n\t(No symbol) [0x00478F2D]\n\tGetHandleVerifier [0x00818E3A+2540266]\n\tGetHandleVerifier [0x00858959+2801161]\n\tGetHandleVerifier [0x0085295C+2776588]\n\tGetHandleVerifier [0x00642280+612144]\n\t(No symbol) [0x00554F6C]\n\t(No symbol) [0x005511D8]\n\t(No symbol) [0x005512BB]\n\t(No symbol) [0x00544857]\n\tBaseThreadInitThunk [0x75CA7D49+25]\n\tRtlInitializeExceptionChain [0x7723B74B+107]\n\tRtlClearBits [0x7723B6CF+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [124]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#entering designation and location as required in the question-\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m designation\u001b[38;5;241m=\u001b[39m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm1-search-form\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m      4\u001b[0m designation\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpensive cars in the world\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:831\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    828\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    829\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".m1-search-form\"}\n  (Session info: chrome=113.0.5672.64)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x005B8893+48451]\n\t(No symbol) [0x0054B8A1]\n\t(No symbol) [0x00455058]\n\t(No symbol) [0x00480467]\n\t(No symbol) [0x0048069B]\n\t(No symbol) [0x004ADD92]\n\t(No symbol) [0x0049A304]\n\t(No symbol) [0x004AC482]\n\t(No symbol) [0x0049A0B6]\n\t(No symbol) [0x00477E08]\n\t(No symbol) [0x00478F2D]\n\tGetHandleVerifier [0x00818E3A+2540266]\n\tGetHandleVerifier [0x00858959+2801161]\n\tGetHandleVerifier [0x0085295C+2776588]\n\tGetHandleVerifier [0x00642280+612144]\n\t(No symbol) [0x00554F6C]\n\t(No symbol) [0x005511D8]\n\t(No symbol) [0x005512BB]\n\t(No symbol) [0x00544857]\n\tBaseThreadInitThunk [0x75CA7D49+25]\n\tRtlInitializeExceptionChain [0x7723B74B+107]\n\tRtlClearBits [0x7723B6CF+191]\n"
     ]
    }
   ],
   "source": [
    "#entering designation and location as required in the question-\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"m1-search-form\") \n",
    "designation.send_keys('expensive cars in the world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7c4de682",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=113.0.5672.64)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x005B8893+48451]\n\t(No symbol) [0x0054B8A1]\n\t(No symbol) [0x00454F20]\n\t(No symbol) [0x0047CB96]\n\t(No symbol) [0x0047C401]\n\t(No symbol) [0x0049A2BC]\n\t(No symbol) [0x00479586]\n\t(No symbol) [0x0049A614]\n\t(No symbol) [0x004AC482]\n\t(No symbol) [0x0049A0B6]\n\t(No symbol) [0x00477E08]\n\t(No symbol) [0x00478F2D]\n\tGetHandleVerifier [0x00818E3A+2540266]\n\tGetHandleVerifier [0x00858959+2801161]\n\tGetHandleVerifier [0x0085295C+2776588]\n\tGetHandleVerifier [0x00642280+612144]\n\t(No symbol) [0x00554F6C]\n\t(No symbol) [0x005511D8]\n\t(No symbol) [0x005512BB]\n\t(No symbol) [0x00544857]\n\tBaseThreadInitThunk [0x75CA7D49+25]\n\tRtlInitializeExceptionChain [0x7723B74B+107]\n\tRtlClearBits [0x7723B6CF+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [94]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m location\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[3]/div[5]/div/div[1]/div[1]/a/picture/img\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mlocation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthe world \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webelement.py:231\u001b[0m, in \u001b[0;36mWebElement.send_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    228\u001b[0m             remote_files\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload(file))\n\u001b[0;32m    229\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remote_files)\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSEND_KEYS_TO_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys_to_typing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys_to_typing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webelement.py:403\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    401\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    402\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=113.0.5672.64)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x005B8893+48451]\n\t(No symbol) [0x0054B8A1]\n\t(No symbol) [0x00454F20]\n\t(No symbol) [0x0047CB96]\n\t(No symbol) [0x0047C401]\n\t(No symbol) [0x0049A2BC]\n\t(No symbol) [0x00479586]\n\t(No symbol) [0x0049A614]\n\t(No symbol) [0x004AC482]\n\t(No symbol) [0x0049A0B6]\n\t(No symbol) [0x00477E08]\n\t(No symbol) [0x00478F2D]\n\tGetHandleVerifier [0x00818E3A+2540266]\n\tGetHandleVerifier [0x00858959+2801161]\n\tGetHandleVerifier [0x0085295C+2776588]\n\tGetHandleVerifier [0x00642280+612144]\n\t(No symbol) [0x00554F6C]\n\t(No symbol) [0x005511D8]\n\t(No symbol) [0x005512BB]\n\t(No symbol) [0x00544857]\n\tBaseThreadInitThunk [0x75CA7D49+25]\n\tRtlInitializeExceptionChain [0x7723B74B+107]\n\tRtlClearBits [0x7723B6CF+191]\n"
     ]
    }
   ],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[3]/div[5]/div/div[1]/div[1]/a/picture/img')\n",
    "location.send_keys('the world ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a6f665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
